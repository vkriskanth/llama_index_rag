{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01335fcf-6853-414f-b4b5-0306b9df5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9177d075-67e1-47ce-8745-38423f99a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a98d59-21bc-497d-8660-a7c42390ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-11 04:14:16--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16911937 (16M) [application/pdf]\n",
      "Saving to: ‘metagpt.pdf’\n",
      "\n",
      "metagpt.pdf         100%[===================>]  16.13M  22.4MB/s    in 0.7s    \n",
      "\n",
      "2024-05-11 04:14:18 (22.4 MB/s) - ‘metagpt.pdf’ saved [16911937/16911937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33807f96-49d0-4ec3-aa4e-f54b1df348d2",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b37b288-769b-4865-b1c1-9404eb4a2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "#Load docs\n",
    "documents = SimpleDirectoryReader(input_files = [\"metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc508746-6c49-423b-abc8-640d3ff92a4f",
   "metadata": {},
   "source": [
    "## Define LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16eb970-fcfc-4339-8076-61eac9f681b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "splitter = SentenceSplitter(chunk_size = 1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfceba8-421c-4101-8cd2-efd9811af8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model = \"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba2718-ead0-40eb-b1f7-f6c893e13eff",
   "metadata": {},
   "source": [
    "## Define Summary and vector index on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b63671f1-6655-4741-a713-a56c90b64d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db656d-e147-4b63-8f54-3f5e5d9ac462",
   "metadata": {},
   "source": [
    "## Define Query engines and set metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5ffa972-2893-42ba-b78c-1355f78d6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode = \"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "\n",
    "vector_query_engine = vector_index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6ff500-bf21-40e4-b51d-57a5e7182850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description = (\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine = vector_query_engine,\n",
    "    description = (\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d1047e-4175-4a84-ba84-37b4f14cd1eb",
   "metadata": {},
   "source": [
    "## Define Router query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1968d3-b9ee-486b-ba80-694851bba5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector = LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88da0934-a9c3-4b40-95ae-406890bb9bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001b[0mThe document introduces MetaGPT, a meta-programming framework for multi-agent collaboration based on Large Language Models (LLMs). It emphasizes role specialization, workflow management, and efficient sharing mechanisms to enhance problem-solving capabilities in software development projects. MetaGPT incorporates Standardized Operating Procedures (SOPs) to streamline workflows, improve code generation quality, and achieve state-of-the-art performance in evaluations. It models a group of agents as a simulated software company, assigning specialized roles and utilizing structured communication interfaces. The document also discusses the performance evaluation of GPT models, ethical concerns, and the benefits of MetaGPT in enabling natural language programming and ensuring transparency, accountability, privacy, and data security.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "268cf50d-d65d-4c75-82ec-685f35832ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd9f34c8-1517-4106-9ed1-2b32918d8dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context from the MetaGPT paper, which would likely include information on how agents share information..\n",
      "\u001b[0mAgents share information with other agents by utilizing a shared message pool where they can publish structured messages. This shared message pool allows all agents to exchange messages directly, enabling them to both publish their own messages and access messages from other agents transparently. Agents can retrieve required information directly from this shared pool, eliminating the need to inquire about other agents and wait for their responses, thus enhancing communication efficiency.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"how do agents share information with other agents?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e865c-77db-495f-9635-4fb2f5f4d4b8",
   "metadata": {},
   "source": [
    "## Eveyrthing together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3a186f2-b613-47b9-95d9-c55280ce03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_router_query_engine\n",
    "query_engine = get_router_query_engine(\"metagpt.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13d3eb8f-96d8-4a9f-996f-c27c12548270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The ablation study results are specific context from the MetaGPT paper, so choice 2 is most relevant..\n",
      "\u001b[0mThe ablation study results provide insights into the impact of different components or features of a system by systematically removing them and observing the effects on the overall performance. This method helps in understanding the contributions of individual elements towards the system's functionality or effectiveness.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620acd7-21a5-4c57-a0da-3986ad75a174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
