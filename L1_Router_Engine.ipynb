{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01335fcf-6853-414f-b4b5-0306b9df5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "OPENAI_API_KEY = get_openai_api_key()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9177d075-67e1-47ce-8745-38423f99a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a98d59-21bc-497d-8660-a7c42390ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-11 04:14:16--  https://openreview.net/pdf?id=VtmBAGCN7o\n",
      "Resolving openreview.net (openreview.net)... 35.184.86.251\n",
      "Connecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16911937 (16M) [application/pdf]\n",
      "Saving to: ‘metagpt.pdf’\n",
      "\n",
      "metagpt.pdf         100%[===================>]  16.13M  22.4MB/s    in 0.7s    \n",
      "\n",
      "2024-05-11 04:14:18 (22.4 MB/s) - ‘metagpt.pdf’ saved [16911937/16911937]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33807f96-49d0-4ec3-aa4e-f54b1df348d2",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b37b288-769b-4865-b1c1-9404eb4a2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "#Load docs\n",
    "#file = \"metagpt.pdf\"\n",
    "file = \"table.pdf\"\n",
    "documents = SimpleDirectoryReader(input_files = [file]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc508746-6c49-423b-abc8-640d3ff92a4f",
   "metadata": {},
   "source": [
    "## Define LLM and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16eb970-fcfc-4339-8076-61eac9f681b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "splitter = SentenceSplitter(chunk_size = 1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecfceba8-421c-4101-8cd2-efd9811af8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model = \"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba2718-ead0-40eb-b1f7-f6c893e13eff",
   "metadata": {},
   "source": [
    "## Define Summary and vector index on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b63671f1-6655-4741-a713-a56c90b64d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db656d-e147-4b63-8f54-3f5e5d9ac462",
   "metadata": {},
   "source": [
    "## Define Query engines and set metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ffa972-2893-42ba-b78c-1355f78d6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode = \"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "\n",
    "vector_query_engine = vector_index.as_query_engine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6ff500-bf21-40e4-b51d-57a5e7182850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "# summary_tool = QueryEngineTool.from_defaults(\n",
    "#     query_engine=summary_query_engine,\n",
    "#     description = (\n",
    "#         \"Useful for summarization questions related to MetaGPT\"\n",
    "#     ),\n",
    "# )\n",
    "# vector_tool = QueryEngineTool.from_defaults(\n",
    "#     query_engine = vector_query_engine,\n",
    "#     description = (\n",
    "#         \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "#     ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d868f83-033f-40ec-b106-4e6317beb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description = (\n",
    "        \"Useful for summarization questions related to disability\"\n",
    "    ),\n",
    ")\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine = vector_query_engine,\n",
    "    description = (\n",
    "        \"Useful for retrieving specific context from the disability table.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d1047e-4175-4a84-ba84-37b4f14cd1eb",
   "metadata": {},
   "source": [
    "## Define Router query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa1968d3-b9ee-486b-ba80-694851bba5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector = LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88da0934-a9c3-4b40-95ae-406890bb9bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The document is likely focused on summarization questions related to disability..\n",
      "\u001b[0mThe document contains an example table displaying data related to different disability categories, including the number of participants, ballots completed, incomplete/terminated ballots, results accuracy, and time taken to complete tasks for each category. The disability categories mentioned are Blind, Low Vision, Dexterity, and Mobility. The table provides specific data points for each category, such as the number of participants, ballots completed, incomplete/terminated ballots, results accuracy in percentage with corresponding sample sizes, and the time taken to complete tasks in seconds with corresponding sample sizes.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "268cf50d-d65d-4c75-82ec-685f35832ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd9f34c8-1517-4106-9ed1-2b32918d8dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it specifically mentions retrieving specific context from the MetaGPT paper, which would likely include information on how agents share information..\n",
      "\u001b[0mAgents share information with other agents by utilizing a shared message pool where they can publish structured messages. This shared message pool allows all agents to exchange messages directly, enabling them to both publish their own messages and access messages from other agents transparently. Agents can retrieve required information directly from this shared pool, eliminating the need to inquire about other agents and wait for their responses, thus enhancing communication efficiency.\n"
     ]
    }
   ],
   "source": [
    "# response = query_engine.query(\n",
    "#     \"how do agents share information with other agents?\")\n",
    "# print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd20651c-1e3c-4456-9a65-aee7a1a40cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The first choice is most relevant as it specifically mentions summarization questions related to disability, which would likely include information about blind disability..\n",
      "\u001b[0mThe blind disability category had 5 participants, with 1 completing all ballots and 4 ballots being incomplete or terminated. The results accuracy for this category was 34.5% based on one completed ballot. The average time taken to complete the tasks for this category was 1199 seconds.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"tell me info about blind disability\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8e865c-77db-495f-9635-4fb2f5f4d4b8",
   "metadata": {},
   "source": [
    "## Eveyrthing together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3a186f2-b613-47b9-95d9-c55280ce03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import get_router_query_engine\n",
    "# query_engine = get_router_query_engine(\"metagpt.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5bbe2a6-9672-4a31-b40d-52beb282cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_router_query_engine\n",
    "query_engine = get_router_query_engine(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13d3eb8f-96d8-4a9f-996f-c27c12548270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: The total number of participants is specific context that can be retrieved from the MetaGPT paper..\n",
      "\u001b[0mThe total number of participants across all disability categories is 18.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the total number of participants\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620acd7-21a5-4c57-a0da-3986ad75a174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
